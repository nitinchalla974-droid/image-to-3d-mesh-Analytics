{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRjvMGD7Ygj1"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/facebookresearch/sam-3d-body.git\n",
        "%cd /content/sam-3d-body"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U pip\n",
        "\n",
        "# Core\n",
        "!pip -q install \"numpy>=2.0\" opencv-python-headless tqdm\n",
        "\n",
        "# Required/common deps (NO xtcocotools)\n",
        "!pip -q install \\\n",
        "  pyrootutils omegaconf huggingface_hub loguru yacs \\\n",
        "  pytorch-lightning pyrender scikit-image einops timm dill pandas rich \\\n",
        "  hydra-core hydra-submitit-launcher hydra-colorlog webdataset \\\n",
        "  chump networkx roma joblib seaborn wandb appdirs cython jsonlines \\\n",
        "  pytest optree fvcore pycocotools tensorboard"
      ],
      "metadata": {
        "id": "h-XjPn52Yx_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y iopath\n",
        "!pip install \"iopath==0.1.9\""
      ],
      "metadata": {
        "id": "iI4wbaALep1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install 'git+https://github.com/facebookresearch/detectron2.git@a1ce2f9' --no-build-isolation --no-deps\n",
        "\n",
        "# Install the deps detectron2 complained about\n",
        "!pip -q install black \"fvcore>=0.1.5,<0.1.6\" \"hydra-core>=1.1\" \"yacs>=0.1.8\"\n",
        "\n",
        "# Detectron2 expects iopath < 0.1.10\n",
        "!pip -q install \"iopath==0.1.9\""
      ],
      "metadata": {
        "id": "G1XmR8fqY0l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, cv2, torch\n",
        "print(\"numpy:\", np.__version__)\n",
        "print(\"cv2:\", cv2.__version__)\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"cuda available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "GFxfkZGrY20a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import logout, login\n",
        "\n",
        "logout()\n",
        "login()"
      ],
      "metadata": {
        "id": "bCod13Tnr_1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "import os, shutil\n",
        "\n",
        "HF_REPO = \"facebook/sam-3d-body-dinov3\"   # you have access accepted\n",
        "LOCAL_DIR = \"/content/checkpoints/sam-3d-body\"\n",
        "\n",
        "# remove any partial download\n",
        "shutil.rmtree(LOCAL_DIR, ignore_errors=True)\n",
        "os.makedirs(LOCAL_DIR, exist_ok=True)\n",
        "\n",
        "snapshot_download(\n",
        "    repo_id=HF_REPO,\n",
        "    local_dir=LOCAL_DIR,\n",
        "    local_dir_use_symlinks=False,\n",
        ")\n",
        "\n",
        "# Verify required files exist\n",
        "req = {\n",
        "    \"model.ckpt\": os.path.join(LOCAL_DIR, \"model.ckpt\"),\n",
        "    \"model_config.yaml\": os.path.join(LOCAL_DIR, \"model_config.yaml\"),\n",
        "    \"assets/mhr_model.pt\": os.path.join(LOCAL_DIR, \"assets\", \"mhr_model.pt\"),\n",
        "}\n",
        "\n",
        "print(\"=== Required files ===\")\n",
        "for k, p in req.items():\n",
        "    print(k, \"->\", p, \"exists:\", os.path.exists(p))\n",
        "\n",
        "missing = [k for k, p in req.items() if not os.path.exists(p)]\n",
        "if missing:\n",
        "    raise RuntimeError(f\"Missing required files: {missing}. This usually means token lacks gated access permission.\")\n",
        "\n",
        "print(\"\\n=== Found ckpt/yaml/pt files ===\")\n",
        "os.system(f'find {LOCAL_DIR} -maxdepth 3 -type f \\\\( -name \"*.ckpt\" -o -name \"*.yaml\" -o -name \"*.pt\" \\\\) -print')"
      ],
      "metadata": {
        "id": "PJuen9g2Y_LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os, shutil\n",
        "\n",
        "os.makedirs(\"/content/images\", exist_ok=True)\n",
        "\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "    shutil.move(fn, f\"/content/images/{fn}\")\n",
        "\n",
        "print(\"Images:\", os.listdir(\"/content/images\"))"
      ],
      "metadata": {
        "id": "955m4pK4ZAKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install trimesh"
      ],
      "metadata": {
        "id": "YwhunXy9cryI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, inspect, importlib, pkgutil, shutil\n",
        "import numpy as np\n",
        "import torch\n",
        "import trimesh\n",
        "\n",
        "import sam_3d_body\n",
        "from sam_3d_body.build_models import load_sam_3d_body\n",
        "\n",
        "# -------------------------\n",
        "# Paths\n",
        "# -------------------------\n",
        "IMG_DIR = \"/content/images\"\n",
        "CKPT_DIR = \"/content/checkpoints/sam-3d-body\"\n",
        "\n",
        "img_path = os.path.join(IMG_DIR, sorted(os.listdir(IMG_DIR))[0])\n",
        "checkpoint_path = os.path.join(CKPT_DIR, \"model.ckpt\")\n",
        "config_path = os.path.join(CKPT_DIR, \"model_config.yaml\")\n",
        "mhr_path = os.path.join(CKPT_DIR, \"assets\", \"mhr_model.pt\")\n",
        "\n",
        "assert os.path.exists(img_path), f\"Missing image: {img_path}\"\n",
        "assert os.path.exists(checkpoint_path), f\"Missing ckpt: {checkpoint_path}\"\n",
        "assert os.path.exists(config_path), f\"Missing config: {config_path}\"\n",
        "assert os.path.exists(mhr_path), f\"Missing mhr: {mhr_path}\"\n",
        "\n",
        "# -------------------------\n",
        "# 1) Find SAM3DBodyEstimator in your installed package\n",
        "# -------------------------\n",
        "SAM3DBodyEstimator = None\n",
        "found_in = None\n",
        "\n",
        "for m in pkgutil.walk_packages(sam_3d_body.__path__, prefix=sam_3d_body.__name__ + \".\"):\n",
        "    try:\n",
        "        mod = importlib.import_module(m.name)\n",
        "    except Exception:\n",
        "        continue\n",
        "    if hasattr(mod, \"SAM3DBodyEstimator\"):\n",
        "        SAM3DBodyEstimator = getattr(mod, \"SAM3DBodyEstimator\")\n",
        "        found_in = m.name\n",
        "        break\n",
        "\n",
        "if SAM3DBodyEstimator is None:\n",
        "    raise ModuleNotFoundError(\"Could not find SAM3DBodyEstimator in sam_3d_body package.\")\n",
        "\n",
        "print(\"✅ Found SAM3DBodyEstimator in:\", found_in)\n",
        "\n",
        "# -------------------------\n",
        "# 2) Load model robustly (no assumptions about argument names)\n",
        "# -------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "sig = inspect.signature(load_sam_3d_body)\n",
        "params = sig.parameters\n",
        "\n",
        "# Base kwargs we *might* pass (only if supported by signature)\n",
        "kwargs = {}\n",
        "if \"device\" in params:\n",
        "    kwargs[\"device\"] = device\n",
        "if \"mhr_path\" in params:\n",
        "    kwargs[\"mhr_path\"] = mhr_path\n",
        "\n",
        "# Try to pass config via any supported arg name; otherwise copy to default expected location\n",
        "config_arg_candidates = [\"model_cfg\", \"model_cfg_file\", \"config\", \"config_path\", \"config_file\",\n",
        "                         \"model_config\", \"model_config_path\", \"cfg\", \"cfg_file\"]\n",
        "used_config_arg = None\n",
        "for cand in config_arg_candidates:\n",
        "    if cand in params:\n",
        "        kwargs[cand] = config_path\n",
        "        used_config_arg = cand\n",
        "        break\n",
        "\n",
        "if used_config_arg:\n",
        "    print(\"✅ Passing config via:\", used_config_arg)\n",
        "else:\n",
        "    # Many versions expect it at a default path; your earlier error showed /content/checkpoints/model_config.yaml\n",
        "    os.makedirs(\"/content/checkpoints\", exist_ok=True)\n",
        "    default_expected = \"/content/checkpoints/model_config.yaml\"\n",
        "    shutil.copy(config_path, default_expected)\n",
        "    print(\"✅ load_sam_3d_body has no config arg; copied config to:\", default_expected)\n",
        "\n",
        "# Call load_sam_3d_body with either checkpoint_path kwarg or positional\n",
        "try:\n",
        "    if \"checkpoint_path\" in params:\n",
        "        kwargs[\"checkpoint_path\"] = checkpoint_path\n",
        "        model, model_cfg = load_sam_3d_body(**kwargs)\n",
        "    else:\n",
        "        model, model_cfg = load_sam_3d_body(checkpoint_path, **kwargs)\n",
        "    print(\"✅ Model loaded\")\n",
        "except TypeError as e:\n",
        "    print(\"❌ Failed calling load_sam_3d_body.\")\n",
        "    print(\"Signature:\", sig)\n",
        "    print(\"Tried kwargs:\", kwargs)\n",
        "    raise\n",
        "\n",
        "# -------------------------\n",
        "# 3) Build estimator (constructor names vary)\n",
        "# -------------------------\n",
        "init_sig = inspect.signature(SAM3DBodyEstimator.__init__)\n",
        "init_params = init_sig.parameters\n",
        "\n",
        "est_kwargs = {}\n",
        "# fill only supported names\n",
        "for name in init_params.keys():\n",
        "    if name == \"self\":\n",
        "        continue\n",
        "    if name in (\"sam_3d_body_model\", \"model\"):\n",
        "        est_kwargs[name] = model\n",
        "    elif name in (\"model_cfg\", \"cfg\"):\n",
        "        est_kwargs[name] = model_cfg\n",
        "\n",
        "estimator = SAM3DBodyEstimator(**est_kwargs)\n",
        "print(\"✅ Estimator ready\")\n",
        "\n"
      ],
      "metadata": {
        "id": "014CHyg2upQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import trimesh\n",
        "\n",
        "# ==========================\n",
        "# 4) Run inference\n",
        "# ==========================\n",
        "outputs = estimator.process_one_image(img_path)\n",
        "print(\"✅ Inference done. Output type:\", type(outputs))\n",
        "print(\"Number of people detected:\", len(outputs) if isinstance(outputs, list) else 1)\n",
        "\n",
        "# ==========================\n",
        "# 5) Extract verts + faces (FIXED)\n",
        "# ==========================\n",
        "if isinstance(outputs, list):\n",
        "    if len(outputs) == 0:\n",
        "        raise RuntimeError(\"No person detected in the image!\")\n",
        "    result = outputs[0]          # take the first (usually the only) person\n",
        "else:\n",
        "    result = outputs\n",
        "\n",
        "# Correct key for vertices\n",
        "verts = result['pred_vertices']   # ← THIS is the right key\n",
        "\n",
        "# Faces come from the estimator (standard for this model)\n",
        "if hasattr(estimator, 'faces'):\n",
        "    faces = estimator.faces\n",
        "elif hasattr(estimator, 'mesh_faces'):\n",
        "    faces = estimator.mesh_faces\n",
        "else:\n",
        "    raise AttributeError(\"Could not find faces on estimator. Check estimator.__dict__.keys()\")\n",
        "\n",
        "def to_numpy(x):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x.detach().cpu().numpy()\n",
        "    return np.asarray(x)\n",
        "\n",
        "verts = to_numpy(verts)\n",
        "faces = to_numpy(faces)\n",
        "\n",
        "print(\"Vertices shape:\", verts.shape)\n",
        "print(\"Faces shape:\", faces.shape)\n",
        "\n",
        "# ==========================\n",
        "# 6) Export OBJ\n",
        "# ==========================\n",
        "os.makedirs(\"/content/output_mesh\", exist_ok=True)\n",
        "obj_path = \"/content/output_mesh/avatar.obj\"\n",
        "\n",
        "mesh = trimesh.Trimesh(vertices=verts, faces=faces, process=False)\n",
        "mesh.export(obj_path)\n",
        "\n",
        "print(\"✅ Mesh successfully saved:\", obj_path)\n",
        "print(\"Download it with:\")\n",
        "from google.colab import files\n",
        "files.download(obj_path)"
      ],
      "metadata": {
        "id": "MbI2oomryHXS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}